from flask import Flask, request, jsonify
from flask_cors import CORS
import fitz   # PyMuPDF
import pdfplumber
import os
from openai import OpenAI
from modules.chart import generate_chart_data
from datetime import datetime
from zoneinfo import ZoneInfo

app = Flask(__name__)
CORS(app)

# Configura cliente OpenAI
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# Mem√≥ria tempor√°ria para chat
ultimo_embarque = None
ultimo_temp_text = ""
ultimo_sm_text = ""

@app.route('/health', methods=['GET'])
def health():
    return jsonify(status="ok"), 200

@app.route('/')
def home():
    return 'Coldchain backend est√° no ar! üöÄ'

@app.route('/analisar', methods=['POST'])
def analisar():
    global ultimo_embarque, ultimo_temp_text, ultimo_sm_text

    embarque = request.form.get('embarque')
    temp_pdf = request.files.get('relatorio_temp')
    sm_pdf = request.files.get('solicitacao_sm')

    if not embarque or not temp_pdf or not sm_pdf:
        return jsonify({'error': 'Faltam dados no formul√°rio'}), 400

    try:
        # 1) Extrai textos brutos dos PDFs
        temp_text = ""
        with fitz.open(stream=temp_pdf.read(), filetype="pdf") as doc:
            for page in doc:
                temp_text += page.get_text()

        sm_pdf.stream.seek(0)
        sm_text = ""
        with pdfplumber.open(sm_pdf.stream) as pdf:
            for page in pdf.pages:
                sm_text += page.extract_text() or ""

        # 2) Gera payload do gr√°fico via m√≥dulo
        extracted = {
            'relatorio_temp': temp_text,
            'solicitacao_sm': sm_text
        }
        grafico = generate_chart_data(extracted)

        # (Opcional) Extrai texto do CTE se enviado
        cte_text = ""
        cte_pdf = request.files.get('cte')
        if cte_pdf:
            try:
                # tenta extrair texto via PyMuPDF
                cte_bytes = cte_pdf.read()
                with fitz.open(stream=cte_bytes, filetype='pdf') as doc_cte:
                    for p in doc_cte:
                        cte_text += p.get_text()
            except Exception:
                cte_text = ""

        # 3) Armazena para contexto de chat (limita tamanho)
        ultimo_embarque = embarque
        ultimo_temp_text = temp_text[:3000]
        ultimo_sm_text = sm_text[:3000]

        # 4) Prompt final para relat√≥rio executivo com estrutura customizada e extra√ß√£o
        agora = datetime.now(ZoneInfo("America/Sao_Paulo")).strftime("%d/%m/%Y %H:%M:%S")
        final_prompt = f"""
1. Cabe√ßalho
   - **T√≠tulo**: An√°lise de Embarque com Temperatura Controlada
   - **Data/Hora**: {agora} (Hor√°rio de Bras√≠lia)
   - **Verifica√ß√£o**: Se algum campo do cabe√ßalho n√£o for encontrado nos relat√≥rios, escreva ‚ÄúN√£o encontrado‚Äù.

2. Origem e Destino
   A partir dos seguintes textos (incluindo o CTE se dispon√≠vel), extraia ou escreva ‚ÄúN√£o encontrado‚Äù quando a informa√ß√£o n√£o estiver dispon√≠vel:

RELAT√ìRIO DE TEMPERATURA:
{ultimo_temp_text}

RELAT√ìRIO SM:
{ultimo_sm_text}

CTE ‚Äì Conhecimento de Embarque:
{cte_text}

   | Campo                  | Valor                                |
   |------------------------|--------------------------------------|
   | Cliente Origem         |                                      |
   | Cliente Destino        |                                      |
   | Transportadora         |                                      |
   | Cidade Origem          |                                      |
   | Endere√ßo Origem        |                                      |
   | Cidade Destino         |                                      |
   | Endere√ßo Destino       |                                      |
   | Prev. Coleta           |                                      |
   | Prev. Entrega          |                                      |

3. Dados da Carga
   - **Material**: extraia do relat√≥rio ou escreva ‚ÄúN√£o encontrado‚Äù
   - **Faixa de Temperatura**: {grafico['yMin']} a {grafico['yMax']} ¬∞C

4. Avalia√ß√£o dos Eventos
   Forne√ßa uma avalia√ß√£o detalhada de como se comportou a temperatura durante o transporte,
   destacando excurs√µes, pontos cr√≠ticos e varia√ß√µes relevantes.

### RELAT√ìRIO DE TEMPERATURA
{ultimo_temp_text}

### RELAT√ìRIO SM
{ultimo_sm_text}

### CTE ‚Äì Conhecimento de Embarque
{cte_text}
"""
        exec_resp = client.chat.completions.create
        agora = datetime.now(ZoneInfo("America/Sao_Paulo")).strftime("%d/%m/%Y %H:%M:%S")
        final_prompt = f"""
1. Cabe√ßalho
   - **T√≠tulo**: An√°lise de Embarque com Temperatura Controlada
   - **Data/Hora**: {agora} (Hor√°rio de Bras√≠lia)

2. Origem e Destino
   A partir dos textos abaixo, extraia ou escreva ‚ÄúN√£o encontrado‚Äù quando a informa√ß√£o n√£o estiver dispon√≠vel:

RELAT√ìRIO DE TEMPERATURA:
{ultimo_temp_text}

RELAT√ìRIO SM:
{ultimo_sm_text}

   | Campo                | Valor                               |
   |----------------------|-------------------------------------|
   | Cliente              |                                     |
   | Cidade Origem        |                                     |
   | Endere√ßo Origem      |                                     |
   | Cidade Destino       |                                     |
   | Endere√ßo Destino     |                                     |
   | Prev. Coleta         |                                     |
   | Prev. Entrega        |                                     |

3. Dados da Carga
   - **Material**: extraia do relat√≥rio ou escreva ‚ÄúN√£o encontrado‚Äù
   - **Faixa de Temperatura**: {grafico['yMin']} a {grafico['yMax']} ¬∞C

4. Avalia√ß√£o dos Eventos
   Forne√ßa uma avalia√ß√£o detalhada de como se comportou a temperatura durante o transporte,
   destacando excurs√µes, pontos cr√≠ticos e varia√ß√µes relevantes.

### RELAT√ìRIO DE TEMPERATURA
{ultimo_temp_text}

### RELAT√ìRIO SM
{ultimo_sm_text}
"""
        exec_resp = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system",  "content": "Voc√™ √© um analista experiente em cadeia fria."},
                {"role": "user",    "content": final_prompt}
            ]
        )
        report_md = exec_resp.choices[0].message.content.strip()

        return jsonify(report_md=report_md, grafico=grafico)
    except Exception as e:
        return jsonify(error=str(e)), 500

@app.route('/chat', methods=['POST'])
def chat():
    global ultimo_embarque, ultimo_temp_text, ultimo_sm_text

    data = request.get_json()
    pergunta = data.get("pergunta")
    if not pergunta:
        return jsonify(error="Pergunta n√£o enviada."), 400
    if not ultimo_embarque:
        return jsonify(error="Nenhum embarque analisado."), 400

    contexto = f"""
Voc√™ est√° ajudando com o embarque: {ultimo_embarque}.
Use estes dados:

RELAT√ìRIO DE TEMPERATURA:
{ultimo_temp_text}

RELAT√ìRIO SM:
{ultimo_sm_text}
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Voc√™ √© um especialista em cadeia fria."},
                {"role": "user",   "content": contexto},
                {"role": "user",   "content": pergunta}
            ]
        )
        return jsonify(resposta=resp.choices[0].message.content.strip())
    except Exception as e:
        return jsonify(error=str(e)), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)
